{
    "all_gpus": false,
    "tree_of_thoughts": false,
    "pdf_path": null,
    "planning": false,
    "random_models_on": false,
    "drop_params": true,
    "artifacts_output_path": null,
    "print_on": true,
    "code_interpreter": false,
    "role": "worker",
    "evaluator": null,
    "output_type": "str-all-except-first",
    "loop_interval": 0,
    "tool_choice": "auto",
    "dashboard": false,
    "thinking_tokens": null,
    "top_p": 0.9,
    "reasoning_effort": null,
    "llm_api_key": null,
    "state_save_file_type": "json",
    "output_cleaner": null,
    "stopping_token": "<DONE>",
    "planning_prompt": null,
    "dynamic_temperature_enabled": false,
    "sentiment_analyzer": null,
    "custom_planning_prompt": null,
    "plan_enabled": false,
    "task": null,
    "stopping_func": null,
    "mcp_urls": null,
    "rag_every_loop": false,
    "autosave": false,
    "traceback": null,
    "artifacts_on": false,
    "fallback_models": [],
    "return_history": false,
    "dynamic_loops": false,
    "max_loops": 1,
    "tool_schema": null,
    "log_directory": null,
    "data_memory": null,
    "auto_generate_prompt": false,
    "long_term_memory": null,
    "preset_stopping_token": false,
    "artifacts_file_extension": null,
    "docs_folder": null,
    "tool_retry_attempts": 3,
    "tokenizer": null,
    "saved_state_path": "agent-fj73T5GPpuKcelAGedvFN65eZ38IwfGS_state.json",
    "description": null,
    "frequency_penalty": 0.8,
    "output_raw_json_from_tool_call": false,
    "traceback_handlers": null,
    "custom_exit_command": "exit",
    "id": "agent-5d1aa269a0ae44efa9fcdb7d2af4222a",
    "agent_ops_on": false,
    "load_state_path": null,
    "model_attempts": {},
    "use_cases": null,
    "function_calling_format_type": "OpenAI",
    "time_created": "2025-10-27 21:12:25",
    "multi_modal": null,
    "tool_system_prompt": "\n\n\n    You've been granted tools to assist users by always providing outputs in JSON format for tool usage. \n    Whenever a tool usage is required, you must output the JSON wrapped inside markdown for clarity. \n    Provide a commentary on the tool usage and the user's request and ensure that the JSON output adheres to the tool's schema.\n    \n    Here are some rules:\n    Do not ever use tools that do not have JSON schemas attached to them.\n    Do not use tools that you have not been granted access to.\n    Do not use tools that are not relevant to the task at hand.\n    Do not use tools that are not relevant to the user's request.\n    \n    \n    Here are the guidelines you must follow:\n\n    1. **Output Format**:\n    - All outputs related to tool usage should be formatted as JSON.\n    - The JSON should be encapsulated within triple backticks and tagged as a code block with 'json'.\n\n    2. **Schema Compliance**:\n    - Ensure that the JSON output strictly follows the provided schema for each tool.\n    - Each tool's schema will define the structure and required fields for the JSON output.\n\n    3. **Schema Example**:\n    If a tool named `example_tool` with a schema requires `param1` and `param2`, your response should look like:\n    ```json\n    {\n        \"type\": \"function\",\n        \"function\": {\n        \"name\": \"example_tool\",\n        \"parameters\": {\n            \"param1\": 123,\n            \"param2\": \"example_value\"\n        }\n        }\n    }\n    ```\n\n    4. **Error Handling**:\n    - If there is an error or the information provided by the user is insufficient to generate a valid JSON, respond with an appropriate error message in JSON format, also encapsulated in markdown.\n\n    Remember, clarity and adherence to the schema are paramount. Your primary goal is to ensure the user receives well-structured JSON outputs that align with the tool's requirements.\n\n    ---\n\n    Here is the format you should always follow for your responses involving tool usage:\n\n    ```json\n    {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"<tool_name>\",\n        \"parameters\": {\n            \"param1\": \"<value1>\",\n            \"param2\": \"<value2>\"\n        }\n    }\n    }\n    ```\n\n    Please proceed with your task accordingly.\n\n    ",
    "sop_list": null,
    "timeout": null,
    "show_tool_execution_output": true,
    "streaming_on": false,
    "step_pool": [],
    "dynamic_context_window": true,
    "self_healing_enabled": false,
    "limit_tokens_from_string": null,
    "tools_list_dictionary": null,
    "load_yaml_path": null,
    "user_name": "Human",
    "sop": null,
    "search_algorithm": null,
    "agent_description": null,
    "mcp_url": null,
    "react_on": false,
    "device": "cpu",
    "response_filters": [],
    "llm_base_url": null,
    "parser": null,
    "sentiment_threshold": null,
    "capabilities": null,
    "reasoning_prompt_on": true,
    "transforms": null,
    "name": "State-Test-Agent",
    "system_prompt": "\n    You are an autonomous agent designed to serve users by automating complex tasks, workflows, and activities with precision and intelligence. \n    Agents leverage custom instructions, specialized capabilities, and curated data to optimize large language models for specific domains and use cases.\n    \n    You possess the ability to engage in both internal reasoning and external interactions to achieve optimal results. \n    Through self-reflection and user collaboration, you can break down complex problems, identify optimal solutions, and execute tasks with high efficiency.\n    \n    Your responses must demonstrate:\n    1. Deep understanding of the task context and requirements\n    2. Logical reasoning and systematic problem-solving\n    3. Clear communication and coherent explanations\n    4. Adaptability to user feedback and changing requirements\n    5. Attention to detail and quality in execution\n    \n    Always aim to exceed expectations by delivering comprehensive, well-structured, and contextually appropriate solutions that address both the explicit and implicit needs of the task.\n",
    "return_step_meta": false,
    "workspace_dir": "agent_workspace",
    "list_base_models": null,
    "mode": "standard",
    "current_model_index": 0,
    "metadata_output_type": "json",
    "chain_of_thoughts": false,
    "callback": null,
    "model_name": "gpt-4.1",
    "feedback": [],
    "list_of_pdf": null,
    "reasoning_enabled": false,
    "fallback_model_name": null,
    "created_at": 1761624745.863062,
    "algorithm_of_thoughts": false,
    "tools": null,
    "temperature": 0.5,
    "template": null,
    "custom_loop_condition": null,
    "tags": null,
    "agent_output": null,
    "device_id": 0,
    "retry_interval": 1,
    "do_not_use_cluster_ops": true,
    "print_every_step": false,
    "max_tokens": 4096,
    "all_cores": true,
    "docs": null,
    "tool_call_summary": true,
    "metadata": null,
    "handoffs": null,
    "conversation_schema": null,
    "custom_tools_prompt": null,
    "mcp_config": null,
    "best_of_n": null,
    "logs_to_filename": null,
    "summarize_multiple_images": false,
    "llm_args": null,
    "presence_penalty": 0.6,
    "retry_attempts": 3,
    "interactive": false,
    "verbose": false,
    "rules": null,
    "context_length": 8192,
    "callbacks": null,
    "mcp_configs": null,
    "stopping_condition": null,
    "scheduled_run_date": null,
    "agent_name": "State-Test-Agent",
    "safety_prompt_on": false,
    "memory_chunk_size": 2000,
    "function_calling_type": "json"
}