swarms

pip install swarms
swarms is the most pythonic way of writing cognitive systems. Leveraging pydantic models as output schemas combined with langchain in the backend allows for a seamless integration of llms into your apps. It utilizes OpenAI Functions or LlamaCpp grammars (json-schema-mode) for efficient structured output. In the backend it compiles the swarms syntax into langchain runnables so you can easily invoke, stream or batch process your pipelines.

Open in GitHub Codespaces

from pydantic import BaseModel, Field
from swarms import Anthropic
from swarms import Agent


# Initialize the schema for the person's information
class Schema(BaseModel):
    name: str = Field(..., title="Name of the person")
    agent: int = Field(..., title="Age of the person")
    is_student: bool = Field(..., title="Whether the person is a student")
    courses: list[str] = Field(
        ..., title="List of courses the person is taking"
    )

# Convert the schema to a JSON string
tool_schema = Schema(
    name="Tool Name",
    agent=1,
    is_student=True,
    courses=["Course1", "Course2"],
)

# Define the task to generate a person's information
task = "Generate a person's information based on the following schema:"

# Initialize the agent
agent = Agent(
    agent_name="Person Information Generator",
    system_prompt=(
        "Generate a person's information based on the following schema:"
    ),
    # Set the tool schema to the JSON string -- this is the key difference
    tool_schema=tool_schema,
    llm=Anthropic(),
    max_loops=3,
    autosave=True,
    dashboard=False,
    streaming_on=True,
    verbose=True,
    interactive=True,
    # Set the output type to the tool schema which is a BaseModel
    output_type=tool_schema, # or dict, or str
    metadata_output_type="json",
    # List of schemas that the agent can handle
    list_tool_schemas = [tool_schema],
    function_calling_format_type = "OpenAI",
    function_calling_type = "json" # or soon yaml
)

# Run the agent to generate the person's information
generated_data = agent.run(task)

# Print the generated data
print(f"Generated data: {generated_data}")






Features
ğŸ pythonic
ğŸ”€ easy swap between openai or local models
ğŸ”„ dynamic output types (pydantic models, or primitives)
ğŸ‘ï¸ vision llm support
ğŸ§  langchain_core as backend
ğŸ“ jinja templating for prompts
ğŸ—ï¸ reliable structured output
ğŸ” auto retry parsing
ğŸ”§ langsmith support
ğŸ”„ sync, async, streaming, parallel, fallbacks
ğŸ“¦ gguf download from huggingface
âœ… type hints for all functions and mypy support
ğŸ—£ï¸ chat router component
ğŸ§© composable with langchain LCEL
ğŸ› ï¸ easy error handling
ğŸš¦ enums and literal support
ğŸ“ custom parsing types
Documentation
Checkout the docs here ğŸ‘ˆ

Also highly recommend to try and run the examples in the ./examples folder.

Contribution
You want to contribute? Thanks, that's great! For more information checkout the Contributing Guide. Please run the dev setup to get started:

git clone https://github.com/kyegomez/swarms.git && cd swarms

./dev_setup.sh
About
â›“ï¸ build cognitive systems, pythonic
